{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 摘要\n",
    "\n",
    "Dataset : ChineseDailyNerCorpus \n",
    "\n",
    "Model : Bert(chinese_L-12_H-768_A-12)作為Feature Extractor，抽取出Contextulized Embedding，下游辨識模型採用BiLSTM_CRF進行訓練\n",
    "\n",
    "Want : \n",
    "\n",
    "1. 了解NER的資料多樣性\n",
    "2. ground-truth的分佈情況\n",
    "3. 訓練時間\n",
    "4. 推論時間\n",
    "5. 準確度指標的相關狀況\n",
    "6. 實作上如何訓練\n",
    "\n",
    "[ChineseDailyNerCorpus 下游模型Benchmark](https://colab.research.google.com/drive/1yKo5h1Eszou5_W18-BQvgqGuzK6uyEnd#scrollTo=4LqUOxB0LbmE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:30.689782Z",
     "start_time": "2021-04-19T16:21:29.129925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joetsai/.conda/envs/py37_tf231/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import kashgari\n",
    "import os\n",
    "from os.path import join as PJ\n",
    "import time\n",
    "from kashgari.corpus import ChineseDailyNerCorpus\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# disble the logger\n",
    "kashgari.logger.logger.propagate = False\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:31.521811Z",
     "start_time": "2021-04-19T16:21:30.691461Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:21:31,335 [DEBUG] kashgari - loaded 20864 samples from /home/joetsai/.kashgari/datasets/china-people-daily-ner-corpus/example.train. Sample:\n",
      "x[0]: ['据', '俄', '通', '社', '—', '塔', '斯', '社', '报', '道', '，', '叶', '利', '钦', '特', '别', '指', '出', '，', '米', '洛', '舍', '维', '奇', '是', '在', '同', '他', '会', '谈', '时', '作', '出', '这', '一', '决', '定', '的', '。']\n",
      "y[0]: ['O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "2021-04-20 00:21:31,397 [DEBUG] kashgari - loaded 2318 samples from /home/joetsai/.kashgari/datasets/china-people-daily-ner-corpus/example.dev. Sample:\n",
      "x[0]: ['脚', '下', '有', '路', '，', '一', '定', '要', '闯', '出', '一', '条', '适', '合', '自', '己', '的', '路', '，', '下', '岗', '不', '可', '怕', '，', '精', '神', '不', '能', '垮', '。']\n",
      "y[0]: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "2021-04-20 00:21:31,519 [DEBUG] kashgari - loaded 4636 samples from /home/joetsai/.kashgari/datasets/china-people-daily-ner-corpus/example.test. Sample:\n",
      "x[0]: ['距', '比', '赛', '结', '束', '只', '有', '3', '分', '钟', '时', '，', '申', '花', '队', '1', '4', '号', '队', '员', '申', '思', '利', '用', '一', '个', '角', '球', '机', '会', '，', '在', '禁', '区', '外', '抡', '起', '左', '脚', '猛', '力', '劲', '射', '，', '敲', '开', '万', '达', '城', '门', '，', '将', '比', '分', '扳', '平', '。']\n",
      "y[0]: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = ChineseDailyNerCorpus.load_data(\"train\")\n",
    "valid_x, valid_y = ChineseDailyNerCorpus.load_data(\"validate\")\n",
    "test_x, test_y = ChineseDailyNerCorpus.load_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:31.527617Z",
     "start_time": "2021-04-19T16:21:31.523811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_x), type(train_x[0]), type(train_x[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數量\n",
    "\n",
    "|資料集|數量|\n",
    "|-----|---|\n",
    "|Train|20000+|\n",
    "|Val|2300+|\n",
    "|Test|4500+|\n",
    "\n",
    "\n",
    "## 資料輸入格式 \n",
    "\n",
    "1. train_x : 有包含NER句子的集合，list\n",
    "2. train_x[0] : 第1列NER句子，list\n",
    "3. train_x[0][0] : 簡體中文字，str\n",
    "4. Encoding - BIO(Begin, Inner, Outter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料多樣性\n",
    "\n",
    "NLP-NER 任務應該參考怎樣的資料多樣性?\n",
    "\n",
    "例如 電腦視覺領域會參考以下幾個維度來衡量資料多樣性\n",
    "\n",
    "藉由應用場景的資料多樣性(Testing set)，來規劃訓練集應當涵蓋的多樣性\n",
    "\n",
    "```\n",
    "1. 照片角度\n",
    "2. 光照程度\n",
    "3. 背景複雜程度(單一 --> 複雜)\n",
    "4. 遠近\n",
    "5. 有無遮擋\n",
    "6. 可能的目標物變異\n",
    "7. 可能的誤判\n",
    "```\n",
    "\n",
    "以下考量 : \n",
    "\n",
    "1. 句子長度分佈 : \n",
    "\n",
    "2. Ground-truth的分佈 : \n",
    "\n",
    "    2-1 : NER序列的長度分佈 : \n",
    "\n",
    "    2-2 : NER的種類分佈 : \n",
    "\n",
    "    2-3 : 包含NER的樣本以及為含有NER樣本的比例(Positive vs Negtive?) : \n",
    "    \n",
    "    2-4 : QA 還可以怎麼觀察NER任務的資料多樣性?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:31.684148Z",
     "start_time": "2021-04-19T16:21:31.529233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20864.000000\n",
       "mean        46.931557\n",
       "std         30.077038\n",
       "min          6.000000\n",
       "25%         28.000000\n",
       "50%         40.000000\n",
       "75%         58.000000\n",
       "max        574.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最短的句子\n",
      "['（', '子', '夜', '走', '笔', '）']\n",
      "\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "最長的句子\n",
      "['北', '京', '小', '雨', '1', '8', '℃', '／', '2', '8', '℃', '天', '津', '雷', '阵', '雨', '1', '8', '℃', '／', '2', '8', '℃', '石', '家', '庄', '小', '雨', '转', '阴', '2', '3', '℃', '／', '2', '9', '℃', '太', '原', '小', '雨', '转', '多', '云', '1', '8', '℃', '／', '2', '8', '℃', '呼', '和', '浩', '特', '多', '云', '转', '晴', '1', '4', '℃', '／', '2', '7', '℃', '沈', '阳', '多', '云', '1', '8', '℃', '／', '2', '6', '℃', '大', '连', '多', '云', '1', '8', '℃', '／', '2', '3', '℃', '长', '春', '雷', '阵', '雨', '1', '6', '℃', '／', '2', '6', '℃', '哈', '尔', '滨', '雷', '阵', '雨', '1', '8', '℃', '／', '2', '8', '℃', '上', '海', '中', '雨', '2', '2', '℃', '／', '2', '6', '℃', '南', '京', '阴', '转', '雷', '阵', '雨', '2', '2', '℃', '／', '2', '9', '℃', '杭', '州', '小', '雨', '转', '中', '雨', '2', '2', '℃', '／', '2', '8', '℃', '合', '肥', '中', '雨', '2', '3', '℃', '／', '2', '8', '℃', '福', '州', '小', '雨', '转', '阴', '2', '4', '℃', '／', '2', '7', '℃', '南', '昌', '中', '雨', '2', '0', '℃', '／', '2', '6', '℃', '济', '南', '小', '雨', '转', '中', '雨', '2', '1', '℃', '／', '2', '8', '℃', '青', '岛', '小', '雨', '1', '9', '℃', '／', '2', '2', '℃', '郑', '州', '雷', '阵', '雨', '2', '2', '℃', '／', '2', '9', '℃', '武', '汉', '中', '雨', '转', '大', '雨', '2', '2', '℃', '／', '2', '7', '℃', '长', '沙', '中', '雨', '转', '大', '雨', '2', '3', '℃', '／', '2', '7', '℃', '广', '州', '多', '云', '转', '小', '雨', '2', '8', '℃', '／', '3', '3', '℃', '南', '宁', '中', '雨', '转', '大', '雨', '2', '5', '℃', '／', '2', '9', '℃', '海', '口', '多', '云', '2', '7', '℃', '／', '3', '6', '℃', '成', '都', '小', '雨', '转', '阴', '2', '1', '℃', '／', '2', '8', '℃', '重', '庆', '阴', '转', '多', '云', '2', '4', '℃', '／', '3', '0', '℃', '贵', '阳', '大', '雨', '转', '多', '云', '2', '0', '℃', '／', '2', '5', '℃', '昆', '明', '小', '雨', '转', '中', '雨', '1', '8', '℃', '／', '2', '2', '℃', '拉', '萨', '阴', '转', '多', '云', '1', '4', '℃', '／', '2', '6', '℃', '西', '安', '阴', '2', '4', '℃', '／', '3', '4', '℃', '兰', '州', '雷', '阵', '雨', '1', '9', '℃', '／', '2', '8', '℃', '西', '宁', '雷', '阵', '雨', '1', '1', '℃', '／', '2', '4', '℃', '银', '川', '多', '云', '1', '7', '℃', '／', '2', '8', '℃', '乌', '鲁', '木', '齐', '晴', '1', '9', '℃', '／', '3', '0', '℃', '台', '北', '阴', '转', '多', '云', '2', '5', '℃', '／', '3', '2', '℃', '香', '港', '多', '云', '转', '小', '雨', '2', '7', '℃', '／', '3', '1', '℃', '澳', '门', '多', '云', '转', '小', '雨', '2', '7', '℃', '／', '3', '0', '℃', '东', '京', '阴', '转', '多', '云', '1', '7', '℃', '／', '2', '6', '℃', '曼', '谷', '阴', '2', '7', '℃', '／', '3', '4', '℃', '悉', '尼', '阴', '转', '多', '云', '6', '℃', '／', '1', '1', '℃', '卡', '拉', '奇', '晴', '2', '8', '℃', '／', '3', '7', '℃', '开', '罗', '晴', '2', '0', '℃', '／', '3', '2', '℃', '莫', '斯', '科', '小', '雨', '1', '1', '℃', '／', '1', '8', '℃', '法', '兰', '克', '福', '多', '云', '转', '晴', '1', '3', '℃', '／', '2', '5', '℃', '巴', '黎', '多', '云', '1', '3', '℃', '／', '2', '4', '℃', '伦', '敦', '多', '云', '转', '阴', '1', '2', '℃', '／', '2', '2', '℃', '纽', '约', '多', '云', '2', '0', '℃', '／', '2', '9', '℃']\n",
      "\n",
      "['B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "平均長度的句子\n",
      "['这', '支', '1', '9', '0', '人', '的', '队', '伍', '，', '1', '5', '8', '人', '是', '内', '部', '分', '流', '的', '转', '岗', '职', '工', '，', '3', '2', '人', '是', '来', '自', '太', '原', '其', '他', '1', '6', '家', '企', '业', '的', '下', '岗', '职', '工', '。']\n",
      "\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['由', '于', '缺', '水', '，', '墨', '西', '哥', '受', '到', '荒', '漠', '化', '侵', '袭', '的', '土', '地', '总', '面', '积', '已', '超', '过', '1', '0', '0', '万', '平', '方', '公', '里', '，', '占', '国', '土', '总', '面', '积', '的', '5', '2', '·', '5', '％', '。']\n",
      "\n",
      "['O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence_length = {}\n",
    "for i, sentence in enumerate(train_x):\n",
    "    sentence_length[i] = len(sentence)\n",
    "\n",
    "sentence_length_s = pd.Series(sentence_length)\n",
    "\n",
    "# display(pd.Series(sentence_length_s))\n",
    "display(sentence_length_s.describe())\n",
    "\n",
    "\n",
    "# 平均來說，一個句子大概46個字長\n",
    "# 最少可以到6個字，最多可以到570+個字\n",
    "\n",
    "print('最短的句子')\n",
    "min_length_idx = sentence_length_s.idxmin()\n",
    "print(train_x[min_length_idx], train_y[min_length_idx], sep='\\n\\n')\n",
    "\n",
    "print('-'*100)\n",
    "\n",
    "print('最長的句子')\n",
    "max_length_idx = sentence_length_s.idxmax()\n",
    "print(train_x[max_length_idx], train_y[max_length_idx], sep='\\n\\n')\n",
    "\n",
    "print('-'*100)\n",
    "\n",
    "print('平均長度的句子')\n",
    "avg_length_idx_list = sentence_length_s[sentence_length_s == 46].index.tolist()\n",
    "\n",
    "avg_length_idx_sample = random.choices(avg_length_idx_list,k=2)\n",
    "\n",
    "for avg_length_idx in avg_length_idx_sample:\n",
    "    print(train_x[avg_length_idx], train_y[avg_length_idx], sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:31.773511Z",
     "start_time": "2021-04-19T16:21:31.685574Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def show_x_y(idx):\n",
    "    print(train_x[idx],train_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:31.881668Z",
     "start_time": "2021-04-19T16:21:31.776405Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def reset_ner_detector():\n",
    "    detect_ner = False\n",
    "    detect_ner_start = 0\n",
    "    detect_ner_end = 0\n",
    "    return detect_ner, detect_ner_start, detect_ner_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:31.990381Z",
     "start_time": "2021-04-19T16:21:31.884355Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def log_ner_stats(ner_d,sentence_i, x, y):\n",
    "    ner_d['sentence_i'].append(sentence_i)\n",
    "    ner_d['x'].append(x)\n",
    "    ner_d['y'].append(y)\n",
    "    return ner_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:32.735017Z",
     "start_time": "2021-04-19T16:21:31.995199Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Ground-truth 類別分佈\n",
    "## Y-sequence-length\n",
    "## Y-category-type\n",
    "## Contain Y, not Contain Y\n",
    "\n",
    "padding = 0\n",
    "ner_d = {\n",
    "    'sentence_i':[],\n",
    "    'x':[],\n",
    "    'y':[]\n",
    "}\n",
    "\n",
    "for sentence_i,(sentecne,sentence_y) in enumerate(zip(train_x[:],train_y[:])):\n",
    "    sentecne_np = np.array(sentecne)\n",
    "    sentecne_y_np = np.array(sentence_y)\n",
    "    detect_ner, detect_ner_start, detect_ner_end = reset_ner_detector()\n",
    "    for char_i, char_y in enumerate(sentecne_y_np):\n",
    "        # no ner detected\n",
    "        if char_y == 'O' and not detect_ner:\n",
    "            pass\n",
    "        \n",
    "        # get ner end!\n",
    "        elif char_y == 'O' and detect_ner:\n",
    "            detect_ner_end = char_i\n",
    "            \n",
    "            # get padding ner chunk\n",
    "            ner_display_start = detect_ner_start - padding if detect_ner_start - padding > 0 else 0\n",
    "            ner_display_end = detect_ner_end + padding if detect_ner_end + padding < len(sentecne_np) else sentecne_np\n",
    "            ner_chunk_x = sentecne_np[ner_display_start : ner_display_end]\n",
    "            ner_chunk_y = sentecne_y_np[ner_display_start : ner_display_end]\n",
    "            # log ners\n",
    "            ner_d = log_ner_stats(ner_d,\n",
    "                                   sentence_i,\n",
    "                                  ''.join(ner_chunk_x.tolist()),\n",
    "                                   ner_chunk_y.tolist()\n",
    "                                  )\n",
    "            detect_ner, detect_ner_start, detect_ner_end = reset_ner_detector()\n",
    "            \n",
    "            # show ner chunk\n",
    "#             print(sentence_i,ner_chunk_x, ner_chunk_y)\n",
    "\n",
    "        # get ner start\n",
    "        elif char_y != 'O' and not detect_ner:\n",
    "            detect_ner_start = char_i\n",
    "            detect_ner = True\n",
    "        # inside the ner\n",
    "        elif char_y != 'O' and detect_ner:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:33.106380Z",
     "start_time": "2021-04-19T16:21:32.736581Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n rows : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_i</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26207</th>\n",
       "      <td>17155</td>\n",
       "      <td>印尼</td>\n",
       "      <td>[B-LOC, I-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>12781</td>\n",
       "      <td>欧洲</td>\n",
       "      <td>[B-LOC, I-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>3740</td>\n",
       "      <td>中心</td>\n",
       "      <td>[B-ORG, I-ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>3940</td>\n",
       "      <td>货币委员会</td>\n",
       "      <td>[B-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18189</th>\n",
       "      <td>11888</td>\n",
       "      <td>中国京</td>\n",
       "      <td>[B-LOC, I-LOC, B-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>593</td>\n",
       "      <td>崔玉山</td>\n",
       "      <td>[B-PER, I-PER, I-PER]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7672</th>\n",
       "      <td>4964</td>\n",
       "      <td>新疆</td>\n",
       "      <td>[B-LOC, I-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15757</th>\n",
       "      <td>10243</td>\n",
       "      <td>民盟中央</td>\n",
       "      <td>[B-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14462</th>\n",
       "      <td>9330</td>\n",
       "      <td>南亚</td>\n",
       "      <td>[B-LOC, I-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19954</th>\n",
       "      <td>13076</td>\n",
       "      <td>古巴</td>\n",
       "      <td>[B-LOC, I-LOC]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_i      x                                    y\n",
       "26207       17155     印尼                       [B-LOC, I-LOC]\n",
       "19524       12781     欧洲                       [B-LOC, I-LOC]\n",
       "5688         3740     中心                       [B-ORG, I-ORG]\n",
       "5980         3940  货币委员会  [B-ORG, I-ORG, I-ORG, I-ORG, I-ORG]\n",
       "18189       11888    中国京                [B-LOC, I-LOC, B-LOC]\n",
       "896           593    崔玉山                [B-PER, I-PER, I-PER]\n",
       "7672         4964     新疆                       [B-LOC, I-LOC]\n",
       "15757       10243   民盟中央         [B-ORG, I-ORG, I-ORG, I-ORG]\n",
       "14462        9330     南亚                       [B-LOC, I-LOC]\n",
       "19954       13076     古巴                       [B-LOC, I-LOC]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    31857.000000\n",
       "mean         3.437015\n",
       "std          2.277463\n",
       "min          1.000000\n",
       "25%          2.000000\n",
       "50%          3.000000\n",
       "75%          4.000000\n",
       "max         30.000000\n",
       "Name: y_sequence_length, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LOC    14927\n",
       "ORG     9057\n",
       "PER     7873\n",
       "Name: y_cat, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'total data rows : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20864"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'contain ner : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12704"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'not contain ner : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_df = pd.DataFrame(ner_d)\n",
    "\n",
    "# show ners\n",
    "display(\n",
    "    'n rows : ',\n",
    "    ner_df.shape[0],\n",
    "    ner_df.sample(10,random_state=SEED)\n",
    ")\n",
    "\n",
    "## Y-sequence-length\n",
    "ner_df['y_sequence_length'] = ner_df['x'].apply(len)\n",
    "display(ner_df['y_sequence_length'].describe())\n",
    "\n",
    "## Y-category-type\n",
    "ner_df['y_cat'] = ner_df['y'].apply(lambda x : x[0]).str.replace('B-','')\n",
    "display(ner_df['y_cat'].value_counts())\n",
    "\n",
    "## Contain Y, not Contain Y\n",
    "contains_ner_set = set(ner_df['sentence_i'].tolist())\n",
    "\n",
    "\n",
    "display('total data rows : ',\n",
    "        len(train_x),\n",
    "        'contain ner : ',\n",
    "        len(contains_ner_set),\n",
    "        'not contain ner : ',\n",
    "        len(train_x) - len(contains_ner_set)\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model profling\n",
    "\n",
    "\n",
    "## Training & Inference Profiling\n",
    "\n",
    "GPU : GeForce GTX 980 Ti 6G\n",
    "\n",
    "|Task|speed|note|\n",
    "|----|-----|----|\n",
    "|Training|6 mins/epoch|\n",
    "|Inference(GPU)|~100ms|GPU, mean of 50 iterations|\n",
    "|Inference(CPU)|~150ms|CPU, mean of 50 iterations|\n",
    "\n",
    "\n",
    "F1-score : 0.93@Epoch15: [check on monitor](https://wandb.ai/yltsai0609/bert-ner/runs/2hylsyy3/logs?workspace=user-yltsai0609)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:33.182732Z",
     "start_time": "2021-04-19T16:21:33.109701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path :  /home/joetsai/work/yulong/bert_ner\n"
     ]
    }
   ],
   "source": [
    "if os.getcwd() == PJ(\"/home\",\"joetsai\",\"work\",\"yulong\",\"bert_ner\",\"docs\"):\n",
    "    os.chdir('..')\n",
    "print('current path : ',os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:21:40.140859Z",
     "start_time": "2021-04-19T16:21:33.185329Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joetsai/.conda/envs/py37_tf231/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: The 'load_model' function is deprecated, use 'XX_Model.load_model' instead\n",
      "  \n",
      "2021-04-20 00:21:33,502 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-04-20 00:21:33,503 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-04-20 00:21:33,504 [DEBUG] kashgari - config_path       : language_model/bert/chinese_L-12_H-768_A-12/bert_config.json\n",
      "2021-04-20 00:21:33,505 [DEBUG] kashgari - vocab_path      : language_model/bert/chinese_L-12_H-768_A-12/vocab.txt\n",
      "2021-04-20 00:21:33,506 [DEBUG] kashgari - checkpoint_path : language_model/bert/chinese_L-12_H-768_A-12/bert_model.ckpt\n",
      "2021-04-20 00:21:33,507 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]']\n",
      "2021-04-20 00:21:33,508 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "SAVE_MODEL_PREFIX = PJ(\"trained_model\", \"ner_daily_news\")\n",
    "trained_model = kashgari.utils.load_model(SAVE_MODEL_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:24:33.581942Z",
     "start_time": "2021-04-19T16:24:32.405861Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:32,409 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:32,545 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:32,546 [DEBUG] kashgari - predict output argmax: [[0 6 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:32,547 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['保', '定', '一', '中', '分', '校', '领', '导', '向', '品', '学', '兼', '优', '的', '下', '岗', '职', '工', '子', '女', '颁', '发', '奖', '学', '金', '，', '团', '员', '同', '学', '向', '下', '岗', '职', '工', '子', '女', '赠', '送', '学', '习', '用', '具', '。']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:32,663 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:32,664 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:32,665 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['能', '不', '能', '实', '现', '跨', '世', '纪', '的', '宏', '伟', '目', '标', '，', '关', '系', '着', '党', '和', '国', '家', '的', '前', '途', '命', '运', '。']\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:32,783 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:32,784 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:32,785 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['没', '水', '吃', '，', '到', '几', '里', '路', '外', '的', '山', '沟', '沟', '去', '挑', '；', '下', '雨', '天', '山', '陡', '路', '滑', '，', '就', '吃', '房', '檐', '水', '；', '饭', '是', '挂', '面', '，', '菜', '是', '盐', '水', '煮', '黄', '豆', '。']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:32,903 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:32,904 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 4 3 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:32,905 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O']]\n",
      "['库', '内', '保', '安', '、', '防', '灾', '系', '统', '精', '良', '，', '有', '单', '独', '的', '空', '调', '机', '组', '维', '持', '2', '0', '摄', '氏', '度', '恒', '温', '、', '5', '0', '％', '—', '6', '0', '％', '湿', '度', '，', '这', '些', '设', '备', '都', '是', '从', '日', '本', '进', '口', '的', '。']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:33,013 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:33,014 [DEBUG] kashgari - predict output argmax: [[0 4 1 1 1 1 6 2 2 1 1 1 4 4 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:33,015 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O', 'O']]\n",
      "['伊', '重', '申', '尊', '重', '联', '合', '国', '划', '定', '的', '伊', '科', '边', '界']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:33,128 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:33,129 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 5 5 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:33,130 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['今', '本', '《', '列', '子', '》', '是', '魏', '晋', '时', '期', '出', '现', '的', '著', '作', '，', '托', '名', '战', '国', '列', '御', '寇', '所', '著', '，', '至', '今', '搞', '不', '清', '其', '作', '者', '是', '谁', '。']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:33,242 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:33,243 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:33,245 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['他', '们', '决', '心', '学', '一', '技', '之', '长', '，', '铸', '健', '康', '灵', '魂', '，', '重', '新', '做', '人', '，', '以', '实', '际', '行', '动', '报', '答', '母', '亲', '的', '养', '育', '之', '恩', '。']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:33,357 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:33,358 [DEBUG] kashgari - predict output argmax: [[0 4 3 1 1 1 1 1 1 1 4 3 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:33,359 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['桂', '林', '多', '山', '，', '山', '珍', '也', '是', '桂', '林', '菜', '肴', '的', '特', '色', '。']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:33,468 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:33,469 [DEBUG] kashgari - predict output argmax: [[0 1 1 4 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:33,470 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['漫', '游', '佛', '湾', '还', '看', '到', '市', '俗', '化', '很', '浓', '的', '、', '反', '映', '贫', '民', '生', '活', '的', '场', '景', '《', '六', '道', '轮', '回', '图', '》', '，', '有', '融', '儒', '家', '思', '想', '于', '佛', '教', '教', '义', '的', '《', '父', '母', '恩', '重', '经', '变', '图', '》', '，', '还', '有', '说', '明', '宗', '教', '、', '哲', '理', '的', '《', '锁', '六', '耗', '图', '》', '等', '。']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:33,578 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:33,579 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 4 3 1 4 3 1 1 1 1 1 1 1 1 1 4 3 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O']]\n",
      "['与', '上', '年', '相', '比', '，', '巢', '湖', '和', '滇', '池', '污', '染', '程', '度', '有', '所', '加', '重', '，', '太', '湖', '有', '所', '减', '轻', '。']\n"
     ]
    }
   ],
   "source": [
    "smaples = random.choices(\n",
    "    test_x,\n",
    "    k=10,\n",
    ")\n",
    "for sentence in smaples:\n",
    "    print(trained_model.predict([sentence], truncating=True))\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T16:24:41.631680Z",
     "start_time": "2021-04-19T16:24:40.814638Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:40,818 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:40,944 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:40,945 [DEBUG] kashgari - predict output argmax: [[0 7 5 5 1 4 3 3 3 3 3 3 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:40,946 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-PER', 'I-PER', 'I-PER', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O']]\n",
      "['王', '小', '明', '去', '台', '北', '市', '立', '動', '物', '園', '玩']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:41,066 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:41,067 [DEBUG] kashgari - predict output argmax: [[0 4 3 1 4 3 3 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:41,069 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['高', '雄', '的', '西', '子', '灣', '是', '一', '個', '散', '心', '絕', '佳', '的', '好', '去', '處']\n",
      "1/1 [==============================] - 0s 994us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:41,174 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:41,176 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 4 3 3 3 3 3 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:41,176 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O']]\n",
      "['Y', 'C', '來', '到', '了', '桃', '園', '國', '際', '機', '場', '搭', '飛', '機']\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:41,293 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:41,294 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:41,295 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['J', 'o', 'e', '和', 'Y', 'C', '正', '在', 'Z', 'o', 'o', 'm', '進', '行', '兩', '週', '一', '次', '的', '機', '器', '學', '習', '討', '論', '會']\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:41,406 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:41,408 [DEBUG] kashgari - predict output argmax: [[0 4 3 1 4 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:41,409 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['瑜', '隆', '和', '宜', '昌', '正', '在', 'Z', 'o', 'o', 'm', '進', '行', '兩', '週', '一', '次', '的', '機', '器', '學', '習', '討', '論', '會']\n",
      "1/1 [==============================] - 0s 961us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:41,524 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:41,525 [DEBUG] kashgari - predict output argmax: [[0 6 2 2 1 4 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "2021-04-20 00:24:41,525 [DEBUG] kashgari - predict seq_length: 100, input: (2, 1, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "['痞', '客', '邦', '在', '捷', '運', '行', '天', '宮', '站', '附', '近', '，', '走', '路', '大', '概', '1', '0', '分', '鐘', '，', '還', '挺', '遠', '的']\n",
      "1/1 [==============================] - 0s 974us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-20 00:24:41,627 [DEBUG] kashgari - predict output: (1, 100)\n",
      "2021-04-20 00:24:41,629 [DEBUG] kashgari - predict output argmax: [[0 6 2 2 2 1 4 3 1 1 1 1 1 1 4 3 1 4 3 3 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O']]\n",
      "['玉', '山', '銀', '行', '全', '台', '灣', '都', '有', '，', '總', '部', '在', '台', '北', '的', '信', '義', '區', '嗎', '？']\n"
     ]
    }
   ],
   "source": [
    "ood_sentence = [\n",
    "    '王小明去台北市立動物園玩',\n",
    "    '高雄的西子灣是一個散心絕佳的好去處',\n",
    "    \"YC來到了桃園國際機場搭飛機\",\n",
    "    \"Joe和YC正在Zoom進行兩週一次的機器學習討論會\",\n",
    "    \"瑜隆和宜昌正在Zoom進行兩週一次的機器學習討論會\",\n",
    "    \"痞客邦在捷運行天宮站附近，走路大概10分鐘，還挺遠的\",\n",
    "    \"玉山銀行全台灣都有，總部在台北的信義區嗎？\"\n",
    "]\n",
    "\n",
    "\n",
    "for sentecne in ood_sentence:\n",
    "    print(trained_model.predict([list(sentecne)], truncating=True))\n",
    "    print(list(sentecne))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tf231",
   "language": "python",
   "name": "py37_tf231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
